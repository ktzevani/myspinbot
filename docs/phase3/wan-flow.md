# ğŸ§  Talking Avatar Pipeline Specification

### *(With Selectable Generation Variants)*

---

## ğŸ¯ Goal

Generate talking avatar videos from text using:

* A cloned voice (from a reference audio sample)
* A static portrait or character image
* A selectable final animation style:

| Variant       | Output Style                                            | Use Case                                         |
| ------------- | ------------------------------------------------------- | ------------------------------------------------ |
| **Variant A** | Full-body walking / acting **(WAN S2V)**                | AI influencer, vlog-style agent, movement scenes |
| **Variant B** | Talking head / presenter **(InfiniteTalk / MultiTalk)** | Newscaster, narrator, assistant agent            |

A selector node allows switching styles **per render**, without changing the graph.

---

## ğŸ“¦ Architecture Overview

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LAYER 1: Content & Voice Generation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Text â†’ TTS-Audio-Suite â†’ AUDIO (cloned voice)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LAYER 2: Animation Variant Selection
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    A) WAN S2V full-body animation OR  
    B) InfiniteTalk presenter lip-sync

    Selected via ImpactPack â†’ Switch (Any)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LAYER 3: Output Assembly
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Selected IMAGE stream + AUDIO â†’ CreateVideo â†’ Save MP4
```

Audio is generated **once** and reused across variants.

---

## 1ï¸âƒ£ Required Inputs

| Input                      | Source                          | Notes                                 |
| -------------------------- | ------------------------------- | ------------------------------------- |
| **Script text**            | Provided externally             | Any language supported by TTS engine  |
| **Reference voice sample** | Short WAV/MP3 of target speaker | Clean speech only                     |
| **Portrait image**         | FluxMania / custom image        | Used in presenter variant             |
| **Full-body image**        | Generated or provided           | Recommended for walking/avatar motion |

---

## 2ï¸âƒ£ Layer 1 â€” Voice Output via TTS-Audio-Suite

Purpose: Convert the user script to a synthetic voice matching the reference sample.

Pipeline:

```
Text â†’ IndexTTSEngine â†’ UnifiedTTSTextNode â†’ AUDIO
```

Output:

```
AUDIO_STREAM
```

This audio will drive both animation paths.

---

## 3ï¸âƒ£ Layer 2 â€” Animation Variants

Two independent image sequence generators use the same audio.

### â­ Variant A â€” WAN S2V (Walking / Acting)

Purpose: Generate gesture and movement while speaking.

Pipeline:

```
Full-Body Image + AUDIO_STREAM â†’ WAN S2V â†’ Frames
```

Result:

```
IMAGE_STREAM_A
```

Best for:

* Walking scenes
* Influencer-style content
* Action body language

---

### â­ Variant B â€” InfiniteTalk / MultiTalk (Presenter / Talking Head)

Purpose: Stable presenter with synchronized lip-sync and subtle motion.

Pipeline:

```
Portrait Image + AUDIO_STREAM â†’ InfiniteTalk (or MultiTalk) â†’ Frames
```

Result:

```
IMAGE_STREAM_B
```

Ideal for:

* News formats
* Product explainers
* Digital assistant avatars

---

### ğŸ”€ Variant Selector

Uses **ImpactSwitch (Switch Any)**.

```
select = 0 â†’ IMAGE_STREAM_A (WAN S2V)
select = 1 â†’ IMAGE_STREAM_B (InfiniteTalk)
```

Output:

```
SELECTED_IMAGE_STREAM
```

---

## 4ï¸âƒ£ Layer 3 â€” Final Video Assembly

Pipeline:

```
SELECTED_IMAGE_STREAM + AUDIO_STREAM â†’ CreateVideo â†’ SaveVideo (MP4)
```

Output example:

```
/video/output/avatar_<timestamp>.mp4
```

---

## âš™ï¸ Runtime Procedure

| Step | Action                                          |
| ---- | ----------------------------------------------- |
| 1    | Provide text, reference audio, and images       |
| 2    | TTS-Audio-Suite generates cloned-voice audio    |
| 3    | Both animation branches produce image sequences |
| 4    | Set `Variant_Select` to `0` or `1`              |
| 5    | CreateVideo muxes audio + visual                |
| 6    | Save final MP4                                  |

---

## Recommended Settings (16GB GPU)

| Setting           | Value         |
| ----------------- | ------------- |
| FPS               | 16â€“24         |
| Resolution        | 720Ã—1280      |
| Max render length | â‰¤ 120 seconds |
| VRAM mode         | Enabled       |

---

## Future Extensions

| Feature                    | Benefit                    |
| -------------------------- | -------------------------- |
| RIFE interpolation         | Smooth motion              |
| Motion LoRAs               | Consistent gesture control |
| Automatic scene stitching  | Long-form episodes         |
| Real-time voice agent mode | Interactive assistant      |

---

### ğŸ”¥ Final Summary

> The system converts input text into a cloned voice using TTS-Audio-Suite, feeds that audio into two animation pipelines (WAN S2V for full-body movement or InfiniteTalk/MultiTalk for presenter-style talking), switches between them via a selector node, and combines the chosen animation with the audio into a final MP4 video.

---
